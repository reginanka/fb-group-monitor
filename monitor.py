import feedparser
import os
import re
from datetime import datetime, timedelta
from supabase import create_client, Client
import requests

# Supabase
SUPABASE_URL = os.getenv('SUPABASE_URL')
SUPABASE_KEY = os.getenv('SUPABASE_KEY')  # anon/service_role key
supabase: Client = create_client(SUPABASE_URL, SUPABASE_KEY)

RSS_URL = os.getenv('RSS_URL')
TG_BOT_TOKEN = os.getenv('TG_BOT_TOKEN')
TG_CHAT_ID = os.getenv('TG_CHAT_ID')

def extract_first_sentence(text, limit=100):
    """–ü–µ—Ä—à–µ —Ä–µ—á–µ–Ω–Ω—è –∞–±–æ –ø–µ—Ä—à—ñ 100 —Å–∏–º–≤–æ–ª—ñ–≤"""
    if not text:
        return ""
    # –í–∏–¥–∞–ª—è—î–º–æ HTML/–ª—ñ–Ω–∫–∏
    text = re.sub(r'<[^>]+>|https?://\S+', '', text)
    # –ü–µ—Ä—à–µ —Ä–µ—á–µ–Ω–Ω—è
    match = re.match(r'^[^.!?]+[.!?]', text)
    if match:
        return match.group(0)[:limit]
    return text[:limit].strip()

def cleanup_old_posts():
    """–í–∏–¥–∞–ª—è—î –ø–æ—Å—Ç–∏ —Å—Ç–∞—Ä—à—ñ 30 –¥–Ω—ñ–≤"""
    cutoff = (datetime.now() - timedelta(days=30)).isoformat()
    result = supabase.table('group_posts').delete().lt('created_at', cutoff).execute()
    print(f"–í–∏–¥–∞–ª–µ–Ω–æ {len(result.data)} —Å—Ç–∞—Ä–∏—Ö –ø–æ—Å—Ç—ñ–≤")

def check_spam_patterns(user_id, first_sentence):
    """–ü–µ—Ä–µ–≤—ñ—Ä—è—î: –±–∞–≥–∞—Ç–æ –ø–æ—Å—Ç—ñ–≤ + —Å—Ö–æ–∂–∏–π —Ç–µ–∫—Å—Ç"""
    # –û—Å—Ç–∞–Ω–Ω—ñ –ø–æ—Å—Ç–∏ –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–∞ –∑–∞ 24 –≥–æ–¥
    cutoff = (datetime.now() - timedelta(hours=24)).isoformat()
    result = supabase.table('group_posts')\
        .select('first_sentence, created_at')\
        .eq('user_id', user_id)\
        .gte('created_at', cutoff)\
        .execute()
    
    posts = result.data
    if len(posts) > 4:  # >4 –ø–æ—Å—Ç–∏/–¥–µ–Ω—å
        # –ß–∏ —Å—Ö–æ–∂—ñ —Ç–µ–∫—Å—Ç–∏?
        similar = sum(1 for p in posts if p['first_sentence'] == first_sentence)
        if similar > 2:  # –ü–æ–≤—Ç–æ—Ä—é—î —Ç–æ–π —Å–∞–º–∏–π —Ç–µ–∫—Å—Ç
            return True, len(posts), "–î—É–±–ª—ñ–∫–∞—Ç —Ç–µ–∫—Å—Ç—É"
        return True, len(posts), "–ë–∞–≥–∞—Ç–æ –ø–æ—Å—Ç—ñ–≤"
    return False, 0, ""

def send_telegram(message):
    url = f"https://api.telegram.org/bot{TG_BOT_TOKEN}/sendMessage"
    requests.post(url, data={'chat_id': TG_CHAT_ID, 'text': message, 'parse_mode': 'HTML'})

def parse_rss():
    feed = feedparser.parse(RSS_URL)
    
    for entry in feed.entries[-30:]:  # –û—Å—Ç–∞–Ω–Ω—ñ 30
        link = entry.link
        author = entry.get('author', 'Unknown')
        
        # –í–∏—Ç—è–≥—É—î–º–æ user_id –∑ –ª—ñ–Ω–∫—É (—è–∫—â–æ —î)
        user_id_match = re.search(r'user/(\d+)|/profile\.php\?id=(\d+)', link)
        user_id = user_id_match.group(1) or user_id_match.group(2) if user_id_match else author
        
        # –ü–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ —á–∏ —î –≤ –ë–î
        existing = supabase.table('group_posts').select('id').eq('post_link', link).execute()
        if existing.data:
            continue  # –í–∂–µ –æ–±—Ä–æ–±–∏–ª–∏
        
        # –ü–µ—Ä—à–µ —Ä–µ—á–µ–Ω–Ω—è
        text = entry.get('summary', entry.get('title', ''))
        first_sent = extract_first_sentence(text)
        
        # –ó–±–µ—Ä—ñ–≥–∞—î–º–æ
        supabase.table('group_posts').insert({
            'user_id': user_id,
            'user_name': author,
            'post_link': link,
            'first_sentence': first_sent,
        }).execute()
        
        # –ß–µ–∫–∞—î–º–æ —Å–ø–∞–º
        is_spam, count, reason = check_spam_patterns(user_id, first_sent)
        if is_spam:
            message = f"üö® <b>–ü—ñ–¥–æ–∑—Ä—ñ–ª–∞ –∞–∫—Ç–∏–≤–Ω—ñ—Å—Ç—å</b>\n\n"\
                      f"üë§ {author} (ID: {user_id})\n"\
                      f"üìä –ü–æ—Å—Ç—ñ–≤ –∑–∞ 24 –≥–æ–¥: {count}\n"\
                      f"‚ö†Ô∏è –ü—Ä–∏—á–∏–Ω–∞: {reason}\n"\
                      f"üìù –¢–µ–∫—Å—Ç: <i>{first_sent}</i>\n"\
                      f"üîó <a href='{link}'>–ü–µ—Ä–µ–≥–ª—è–Ω—É—Ç–∏ –ø–æ—Å—Ç</a>"
            send_telegram(message)
    
    print(f"RSS –ø–µ—Ä–µ–≤—ñ—Ä–µ–Ω–æ: {len(feed.entries)} –ø–æ—Å—Ç—ñ–≤")

def main():
    cleanup_old_posts()  # –°–ø–æ—á–∞—Ç–∫—É —á–∏—Å—Ç–∏–º–æ
    parse_rss()

if __name__ == "__main__":
    main()
