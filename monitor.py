import requests
from bs4 import BeautifulSoup
import os
import re
from datetime import datetime, timedelta
from supabase import create_client, Client
import time

# Supabase
SUPABASE_URL = os.getenv('SUPABASE_URL')
SUPABASE_KEY = os.getenv('SUPABASE_KEY')
supabase: Client = create_client(SUPABASE_URL, SUPABASE_KEY)

# Telegram
TG_BOT_TOKEN = os.getenv('TG_BOT_TOKEN')
TG_CHAT_ID = os.getenv('TG_CHAT_ID')

# Facebook –≥—Ä—É–ø–∞
GROUP_ID = os.getenv('GROUP_ID')  # ID –∞–±–æ –Ω–∞–∑–≤–∞ –≥—Ä—É–ø–∏
GROUP_URL = f"https://mbasic.facebook.com/groups/{GROUP_ID}"

# –¢–∞–±–ª–∏—Ü—è –¥–ª—è –∑–±–µ—Ä–µ–∂–µ–Ω–Ω—è –æ—Å—Ç–∞–Ω–Ω—å–æ–≥–æ checkpoint
def get_last_checkpoint():
    """–û—Ç—Ä–∏–º—É—î timestamp –æ—Å—Ç–∞–Ω–Ω—å–æ—ó –ø–µ—Ä–µ–≤—ñ—Ä–∫–∏"""
    result = supabase.table('monitor_state')\
        .select('last_check_time')\
        .eq('group_id', GROUP_ID)\
        .execute()
    
    if result.data:
        return datetime.fromisoformat(result.data[0]['last_check_time'])
    else:
        # –ü–µ—Ä—à–∏–π –∑–∞–ø—É—Å–∫ ‚Äî –±–µ—Ä–µ–º–æ 30 –¥–Ω—ñ–≤ –Ω–∞–∑–∞–¥
        return datetime.now() - timedelta(days=30)

def update_checkpoint():
    """–û–Ω–æ–≤–ª—é—î timestamp –æ—Å—Ç–∞–Ω–Ω—å–æ—ó –ø–µ—Ä–µ–≤—ñ—Ä–∫–∏"""
    now = datetime.now().isoformat()
    
    # Upsert (insert –∞–±–æ update)
    supabase.table('monitor_state').upsert({
        'group_id': GROUP_ID,
        'last_check_time': now
    }).execute()

def scrape_facebook_posts(since_time):
    """
    –ü–∞—Ä—Å–∏—Ç—å –ø–æ—Å—Ç–∏ –∑ mbasic.facebook.com
    since_time: datetime ‚Äî –∑ —è–∫–æ–≥–æ —á–∞—Å—É —á–∏—Ç–∞—Ç–∏
    """
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
    }
    
    posts = []
    url = GROUP_URL
    max_pages = 3  # –ú–∞–∫—Å–∏–º—É–º 3 —Å—Ç–æ—Ä—ñ–Ω–∫–∏ (—â–æ–± –Ω–µ —á–∏—Ç–∞—Ç–∏ –≤–µ—Å—å —Ñ—ñ–¥)
    
    for page in range(max_pages):
        try:
            response = requests.get(url, headers=headers, timeout=10)
            if response.status_code != 200:
                print(f"FB –ø–æ–≤–µ—Ä–Ω—É–≤ {response.status_code}, –∑—É–ø–∏–Ω—è—î–º–æ—Å—å")
                break
            
            soup = BeautifulSoup(response.text, 'html.parser')
            
            # –ó–Ω–∞—Ö–æ–¥–∏–º–æ –≤—Å—ñ –ø–æ—Å—Ç–∏ (—Å—Ç—Ä—É–∫—Ç—É—Ä–∞ mbasic)
            # –ü—Ä–∏–º—ñ—Ç–∫–∞: —Å–µ–ª–µ–∫—Ç–æ—Ä–∏ –º–æ–∂—É—Ç—å –∑–º—ñ–Ω—é–≤–∞—Ç–∏—Å—å, —Ç—Ä–µ–±–∞ —Ç–µ—Å—Ç—É–≤–∞—Ç–∏
            post_divs = soup.find_all('div', {'data-ft': True})
            
            found_old_post = False
            
            for post_div in post_divs:
                # –í–∏—Ç—è–≥—É—î–º–æ —á–∞—Å –ø–æ—Å—Ç–∞
                time_elem = post_div.find('abbr')
                if not time_elem:
                    continue
                
                post_time_str = time_elem.get_text()
                post_time = parse_fb_time(post_time_str)
                
                # –Ø–∫—â–æ –ø–æ—Å—Ç —Å—Ç–∞—Ä—ñ—à–∏–π –∑–∞ since_time ‚Äî –∑—É–ø–∏–Ω—è—î–º–æ—Å—å
                if post_time < since_time:
                    found_old_post = True
                    break
                
                # –í–∏—Ç—è–≥—É—î–º–æ –∞–≤—Ç–æ—Ä–∞
                author_elem = post_div.find('h3')
                author = author_elem.get_text() if author_elem else 'Unknown'
                
                # –í–∏—Ç—è–≥—É—î–º–æ —Ç–µ–∫—Å—Ç
                content_elem = post_div.find('div', {'data-ft': True})
                text = content_elem.get_text() if content_elem else ''
                
                # –í–∏—Ç—è–≥—É—î–º–æ –ø–æ—Å–∏–ª–∞–Ω–Ω—è –Ω–∞ –ø–æ—Å—Ç
                link_elem = post_div.find('a', href=True, string=re.compile('Full Story|–ü–æ–≤–Ω–∞ —ñ—Å—Ç–æ—Ä—ñ—è'))
                post_link = 'https://mbasic.facebook.com' + link_elem['href'] if link_elem else GROUP_URL
                
                # –í–∏—Ç—è–≥—É—î–º–æ user_id (—è–∫—â–æ —î –≤ –ª—ñ–Ω–∫—É)
                user_id = extract_user_id(post_div) or author
                
                posts.append({
                    'user_id': user_id,
                    'user_name': author,
                    'text': text,
                    'link': post_link,
                    'timestamp': post_time
                })
            
            if found_old_post:
                print(f"–ó–Ω–∞–π—à–ª–∏ —Å—Ç–∞—Ä–∏–π –ø–æ—Å—Ç, –∑—É–ø–∏–Ω—è—î–º–æ—Å—å –Ω–∞ —Å—Ç–æ—Ä—ñ–Ω—Ü—ñ {page+1}")
                break
            
            # –ù–∞—Å—Ç—É–ø–Ω–∞ —Å—Ç–æ—Ä—ñ–Ω–∫–∞
            next_link = soup.find('a', string=re.compile('See more posts|–ü–æ–∫–∞–∑–∞—Ç–∏ –±—ñ–ª—å—à–µ'))
            if not next_link or not next_link.get('href'):
                break
            
            url = 'https://mbasic.facebook.com' + next_link['href']
            time.sleep(2)  # –ó–∞—Ç—Ä–∏–º–∫–∞ –º—ñ–∂ —Å—Ç–æ—Ä—ñ–Ω–∫–∞–º–∏
            
        except Exception as e:
            print(f"–ü–æ–º–∏–ª–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥—É: {e}")
            break
    
    return posts

def parse_fb_time(time_str):
    """
    –ü–∞—Ä—Å–∏—Ç—å —á–∞—Å –∑ Facebook (–ø—Ä–∏–º—ñ—Ç–∏–≤–Ω–æ)
    –ü—Ä–∏–∫–ª–∞–¥–∏: "5 mins", "2 hrs", "Yesterday at 14:30", "January 20 at 10:00"
    """
    now = datetime.now()
    
    if 'min' in time_str:
        mins = int(re.search(r'\d+', time_str).group())
        return now - timedelta(minutes=mins)
    elif 'hr' in time_str or 'hour' in time_str:
        hrs = int(re.search(r'\d+', time_str).group())
        return now - timedelta(hours=hrs)
    elif 'Yesterday' in time_str or '–í—á–æ—Ä–∞' in time_str:
        return now - timedelta(days=1)
    else:
        # –°–∫–ª–∞–¥–Ω—ñ—à–∏–π –ø–∞—Ä—Å–∏–Ω–≥ ‚Äî –º–æ–∂–Ω–∞ –¥–æ–æ–ø—Ä–∞—Ü—é–≤–∞—Ç–∏
        return now - timedelta(hours=1)

def extract_user_id(post_div):
    """–í–∏—Ç—è–≥—É—î user_id –∑ –ø–æ—Å–∏–ª–∞–Ω–Ω—è –Ω–∞ –ø—Ä–æ—Ñ—ñ–ª—å"""
    profile_link = post_div.find('a', href=re.compile(r'/profile\.php\?id=|/[^/]+\?'))
    if profile_link:
        match = re.search(r'id=(\d+)', profile_link['href'])
        if match:
            return match.group(1)
    return None

def extract_first_sentence(text, limit=100):
    """–ü–µ—Ä—à–µ —Ä–µ—á–µ–Ω–Ω—è –∞–±–æ –ø–µ—Ä—à—ñ 100 —Å–∏–º–≤–æ–ª—ñ–≤"""
    if not text:
        return ""
    text = re.sub(r'<[^>]+>|https?://\S+', '', text)
    match = re.match(r'^[^.!?]+[.!?]', text)
    if match:
        return match.group(0)[:limit]
    return text[:limit].strip()

def check_spam_patterns(user_id, first_sentence):
    """–î–µ—Ç–µ–∫—Ü—ñ—è —Å–ø–∞–º—É"""
    cutoff = (datetime.now() - timedelta(hours=24)).isoformat()
    result = supabase.table('group_posts')\
        .select('first_sentence, created_at')\
        .eq('user_id', user_id)\
        .gte('created_at', cutoff)\
        .execute()
    
    posts = result.data
    if len(posts) > 4:
        similar = sum(1 for p in posts if p['first_sentence'] == first_sentence)
        if similar > 2:
            return True, len(posts), "–î—É–±–ª—ñ–∫–∞—Ç —Ç–µ–∫—Å—Ç—É"
        return True, len(posts), "–ë–∞–≥–∞—Ç–æ –ø–æ—Å—Ç—ñ–≤"
    return False, 0, ""

def send_telegram(message):
    """–ù–∞–¥—Å–∏–ª–∞—î –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è –≤ Telegram"""
    url = f"https://api.telegram.org/bot{TG_BOT_TOKEN}/sendMessage"
    try:
        requests.post(url, data={
            'chat_id': TG_CHAT_ID,
            'text': message,
            'parse_mode': 'HTML',
            'disable_web_page_preview': True
        }, timeout=5)
    except Exception as e:
        print(f"–ü–æ–º–∏–ª–∫–∞ Telegram: {e}")

def process_posts(posts):
    """–û–±—Ä–æ–±–∫–∞ —Ç–∞ –∑–±–µ—Ä–µ–∂–µ–Ω–Ω—è –ø–æ—Å—Ç—ñ–≤"""
    new_count = 0
    spam_count = 0
    
    for post in posts:
        # –ü–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ —á–∏ —î –≤ –ë–î
        existing = supabase.table('group_posts')\
            .select('id')\
            .eq('post_link', post['link'])\
            .execute()
        
        if existing.data:
            continue
        
        # –ó–±–µ—Ä—ñ–≥–∞—î–º–æ
        first_sent = extract_first_sentence(post['text'])
        
        try:
            supabase.table('group_posts').insert({
                'user_id': post['user_id'],
                'user_name': post['user_name'],
                'post_link': post['link'],
                'first_sentence': first_sent,
                'created_at': post['timestamp'].isoformat()
            }).execute()
            new_count += 1
        except Exception as e:
            print(f"–ü–æ–º–∏–ª–∫–∞ –∑–∞–ø–∏—Å—É –≤ –ë–î: {e}")
            continue
        
        # –î–µ—Ç–µ–∫—Ü—ñ—è —Å–ø–∞–º—É
        is_spam, count, reason = check_spam_patterns(post['user_id'], first_sent)
        if is_spam:
            spam_count += 1
            message = f"üö® <b>–ü—ñ–¥–æ–∑—Ä—ñ–ª–∞ –∞–∫—Ç–∏–≤–Ω—ñ—Å—Ç—å</b>\n\n"\
                      f"üë§ {post['user_name']} (ID: {post['user_id']})\n"\
                      f"üìä –ü–æ—Å—Ç—ñ–≤ –∑–∞ 24 –≥–æ–¥: {count}\n"\
                      f"‚ö†Ô∏è –ü—Ä–∏—á–∏–Ω–∞: {reason}\n"\
                      f"üìù –¢–µ–∫—Å—Ç: <i>{first_sent}</i>\n"\
                      f"üîó <a href='{post['link']}'>–ü–µ—Ä–µ–≥–ª—è–Ω—É—Ç–∏ –ø–æ—Å—Ç</a>"
            send_telegram(message)
    
    return new_count, spam_count

def main():
    print(f"üöÄ –ó–∞–ø—É—Å–∫ –º–æ–Ω—ñ—Ç–æ—Ä–∏–Ω–≥—É –≥—Ä—É–ø–∏ {GROUP_ID}")
    
    # –û—Ç—Ä–∏–º—É—î–º–æ –æ—Å—Ç–∞–Ω–Ω—ñ–π checkpoint
    last_check = get_last_checkpoint()
    print(f"üìÖ –ß–∏—Ç–∞—î–º–æ –ø–æ—Å—Ç–∏ –ø—ñ—Å–ª—è {last_check}")
    
    # –ü–∞—Ä—Å–∏–º–æ FB
    posts = scrape_facebook_posts(last_check)
    print(f"üìÑ –ó–Ω–∞–π–¥–µ–Ω–æ {len(posts)} –Ω–æ–≤–∏—Ö –ø–æ—Å—Ç—ñ–≤")
    
    # –û–±—Ä–æ–±–ª—è—î–º–æ
    new_count, spam_count = process_posts(posts)
    
    # –û–Ω–æ–≤–ª—é—î–º–æ checkpoint
    update_checkpoint()
    
    print(f"‚úÖ –û–±—Ä–æ–±–ª–µ–Ω–æ: {new_count} –Ω–æ–≤–∏—Ö, {spam_count} —Å–ø–∞–º–µ—Ä—ñ–≤")
    
    # –ü—ñ–¥—Å—É–º–∫–æ–≤–µ –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è
    if new_count > 0:
        summary = f"üìä –ú–æ–Ω—ñ—Ç–æ—Ä–∏–Ω–≥ –∑–∞–≤–µ—Ä—à–µ–Ω–æ\n"\
                  f"–ù–æ–≤–∏—Ö –ø–æ—Å—Ç—ñ–≤: {new_count}\n"\
                  f"–°–ø–∞–º–µ—Ä—ñ–≤: {spam_count}"
        send_telegram(summary)

if __name__ == "__main__":
    main()
